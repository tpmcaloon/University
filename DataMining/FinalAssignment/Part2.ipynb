{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54618dd6",
   "metadata": {},
   "source": [
    "# Data Mining Assignment\n",
    "\n",
    "This assignment represents 100% of the Data Mining module’s mark. It is composed of Part 1 which is worth 40 marks, and Part 2 which is worth 60 marks. You can work in a team of 2 students for this assignment. One student per team will be chosen by the team as being the team leader – who will be in charge of coordinating the team’s work, and of submitting the assignment in their account on VLE on behalf of all the team.\n",
    "\n",
    "# PART 2:\n",
    "\n",
    "This task is based on a real credit risk data, and is to predict a response variable Y which represents a credit card default payment (Yes = 1, No = 0), using the 23 input variables as follows:\n",
    "\n",
    "X1: Amount of the given credit (NT dollar): it includes both the individual consumer credit and his/her family (supplementary) credit.\n",
    "X2: Gender (1 = male; 2 = female).\n",
    "X3: Education (1 = graduate school; 2 = university; 3 = high school; 4 = others).\n",
    "X4: Marital status (1 = married; 2 = single; 3 = others).\n",
    "X5: Age (year).\n",
    "X6 - X11: History of past payment. One tracked the past monthly payment records (from April to September, 2005) as follows: X6 = the repayment status in September, 2005; X7 = the repayment status in August, 2005; . . .;X11 = the repayment status in April, 2005. The measurement scale for the repayment status is: -1 = pay duly; 1 = payment delay for one month; 2 = payment delay for two months; . . .; 8 = payment delay for eight months; 9 = payment delay for nine months and above.\n",
    "X12-X17: Amount of bill statement (NT dollar). X12 = amount of bill statement in September, 2005; X13 = amount of bill statement in August, 2005; . . .; X17 = amount of bill statement in April, 2005.\n",
    "X18-X23: Amount of previous payment (NT dollar). X18 = amount paid in September, 2005; X19 = amount paid in August, 2005; . . .;X23 = amount paid in April, 2005.\n",
    "\n",
    "Two datasets are provided to you: a training dataset in the creditdefault_train.csv file, and a test dataset in the creditdefault_test.csv file.\n",
    "\n",
    "Using Python and any relevant libraries, you are required to build the best predictive model by tuning models using cross validation on the training dataset with each of the following algorithms discussed in this module: k-Nearest Neighbours, Decision Trees, Random Forest, Bagging, AdaBoost, and SVM. Out of the models tuned with the above algorithms, select the best model and clearly justify your choice, and evaluate its performances on the test set.\n",
    "\n",
    "The coding, comments and explanations will be provided in your Python Jupyter notebook called Part2, which should include also the results. Moreover, for each algorithm mentioned above, include 1 chart in the notebook illustrating how accuracy of the models vary when you vary the values of one numeric hyperparameter only (at your choice)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd608c7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN classifier accuracy with 1 neighbors: 0.147\n",
      "KNN classifier accuracy with 2 neighbors: 0.176\n",
      "KNN classifier accuracy with 3 neighbors: 0.193\n",
      "KNN classifier accuracy with 4 neighbors: 0.207\n",
      "KNN classifier accuracy with 5 neighbors: 0.216\n",
      "KNN classifier accuracy with 6 neighbors: 0.224\n",
      "KNN classifier accuracy with 7 neighbors: 0.231\n",
      "KNN classifier accuracy with 8 neighbors: 0.237\n",
      "KNN classifier accuracy with 9 neighbors: 0.240\n",
      "KNN classifier accuracy with 10 neighbors: 0.243\n",
      "KNN classifier accuracy with 11 neighbors: 0.248\n",
      "KNN classifier accuracy with 12 neighbors: 0.249\n",
      "KNN classifier accuracy with 13 neighbors: 0.252\n",
      "KNN classifier accuracy with 14 neighbors: 0.255\n",
      "KNN classifier accuracy with 15 neighbors: 0.255\n",
      "KNN classifier accuracy with 16 neighbors: 0.255\n",
      "KNN classifier accuracy with 17 neighbors: 0.258\n",
      "KNN classifier accuracy with 18 neighbors: 0.258\n",
      "KNN classifier accuracy with 19 neighbors: 0.258\n",
      "KNN classifier accuracy with 20 neighbors: 0.257\n",
      "Decision tree classifier accuracy with max depth 1: 0.235\n",
      "Decision tree classifier accuracy with max depth 2: 0.235\n",
      "Decision tree classifier accuracy with max depth 3: 0.242\n",
      "Decision tree classifier accuracy with max depth 4: 0.250\n",
      "Decision tree classifier accuracy with max depth 5: 0.264\n",
      "Decision tree classifier accuracy with max depth 6: 0.274\n",
      "Decision tree classifier accuracy with max depth 7: 0.278\n",
      "Decision tree classifier accuracy with max depth 8: 0.282\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the training and test datasets\n",
    "train_data = pd.read_csv('creditdefault_train.csv')\n",
    "test_data = pd.read_csv('creditdefault_test.csv')\n",
    "\n",
    "# Split the training data into features and target\n",
    "X_train = train_data.iloc[:, :-1]\n",
    "y_train = train_data.iloc[:, -1]\n",
    "\n",
    "# Split the test data into features and target\n",
    "X_test = test_data.iloc[:, :-1]\n",
    "y_test = test_data.iloc[:, -1]\n",
    "\n",
    "# Define a function to train and evaluate a KNN classifier\n",
    "def train_and_evaluate_knn(k):\n",
    "    # Create a KNN classifier with the specified number of neighbors\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    # Train the classifier on the training data\n",
    "    knn.fit(X_train, y_train)\n",
    "    # Make predictions on the test data\n",
    "    y_pred = knn.predict(X_test)\n",
    "    # Calculate the accuracy of the classifier\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    return acc\n",
    "\n",
    "# Define a function to train and evaluate a decision tree classifier\n",
    "def train_and_evaluate_tree(max_depth):\n",
    "    # Create a decision tree classifier with the specified maximum depth\n",
    "    tree = DecisionTreeClassifier(max_depth=max_depth)\n",
    "    # Train the classifier on the training data\n",
    "    tree.fit(X_train, y_train)\n",
    "    # Make predictions on the test data\n",
    "    y_pred = tree.predict(X_test)\n",
    "    # Calculate the accuracy of the classifier\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    return acc\n",
    "\n",
    "# Define a function to train and evaluate a random forest classifier\n",
    "def train_and_evaluate_forest(n_estimators):\n",
    "    # Create a random forest classifier with the specified number of estimators\n",
    "    forest = RandomForestClassifier(n_estimators=n_estimators)\n",
    "    # Train the classifier on the training data\n",
    "    forest.fit(X_train, y_train)\n",
    "    # Make predictions on the test data\n",
    "    y_pred = forest.predict(X_test)\n",
    "    # Calculate the accuracy of the classifier\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    return acc\n",
    "\n",
    "# Define a list of hyperparameters to try for each algorithm\n",
    "k_values = range(1, 21)\n",
    "depth_values = range(1, 11)\n",
    "n_estimator_values = range(1, 51, 5)\n",
    "\n",
    "# Train and evaluate KNN classifiers with different values of k\n",
    "knn_accuracies = []\n",
    "for k in k_values:\n",
    "    acc = train_and_evaluate_knn(k)\n",
    "    knn_accuracies.append(acc)\n",
    "    print(f\"KNN classifier accuracy with {k} neighbors: {acc:.3f}\")\n",
    "\n",
    "# Train and evaluate decision tree classifiers with different values of max_depth\n",
    "tree_accuracies = []\n",
    "for max_depth in depth_values:\n",
    "    acc = train_and_evaluate_tree(max_depth)\n",
    "    tree_accuracies.append(acc)\n",
    "    print(f\"Decision tree classifier accuracy with max depth {max_depth}: {acc:.3f}\")\n",
    "    \n",
    "# Train and evaluate random forest classifiers with different values of n_estimators\n",
    "forest_accuracies = []\n",
    "for n_estimators in n_estimator_values:\n",
    "    acc = train_and_evaluate_forest(n_estimators)\n",
    "    forest_accuracies.append(acc)\n",
    "    print(f\"Random forest classifier accuracy with {n_estimators} estimators: {acc:.3f}\")\n",
    "\n",
    "# Plot the accuracy of the KNN classifiers as a function of k\n",
    "plt.plot(k_values, knn_accuracies)\n",
    "plt.xlabel('Number of neighbors (k)')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('KNN Classifier Accuracy vs. Number of Neighbors')\n",
    "plt.show()\n",
    "\n",
    "# Plot the accuracy of the decision tree classifiers as a function of max_depth\n",
    "plt.plot(depth_values, tree_accuracies)\n",
    "plt.xlabel('Maximum tree depth')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Decision Tree Classifier Accuracy vs. Maximum Tree Depth')\n",
    "plt.show()\n",
    "\n",
    "# Plot the accuracy of the random forest classifiers as a function of n_estimators\n",
    "plt.plot(n_estimator_values, forest_accuracies)\n",
    "plt.xlabel('Number of Estimators')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Decision Tree Classifier Accuracy vs. Number of Estimators')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(k_values, knn_accuracies, label='KNN')\n",
    "plt.plot(depth_values, tree_accuracies, label='Decision Tree')\n",
    "plt.plot(n_estimator_values, forest_accuracies, label='Random Forest')\n",
    "plt.xlabel('Hyperparameter value')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d078c708",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
